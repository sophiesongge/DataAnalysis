{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    #################################################################\n",
      "        A simple web crawler to find out the top 100 movies in Douban\n",
      "                          Author: Sophie Song\n",
      "                            Version: 0.0.1\n",
      "                           Date: 2018-10-10 16:54:43.105293\n",
      "    #################################################################\n",
      "\n",
      "Ready to crawl Douban's movie data ...\n",
      "Top1 肖申克的救赎\n",
      "Top2 霸王别姬\n",
      "Top3 这个杀手不太冷\n",
      "Top4 阿甘正传\n",
      "Top5 美丽人生\n",
      "Top6 泰坦尼克号\n",
      "Top7 千与千寻\n",
      "Top8 辛德勒的名单\n",
      "Top9 盗梦空间\n",
      "Top10 机器人总动员\n",
      "Top11 忠犬八公的故事\n",
      "Top12 三傻大闹宝莱坞\n",
      "Top13 海上钢琴师\n",
      "Top14 放牛班的春天\n",
      "Top15 大话西游之大圣娶亲\n",
      "Top16 楚门的世界\n",
      "Top17 教父\n",
      "Top18 龙猫\n",
      "Top19 星际穿越\n",
      "Top20 熔炉\n",
      "Top21 无间道\n",
      "Top22 触不可及\n",
      "Top23 当幸福来敲门\n",
      "Top24 乱世佳人\n",
      "Top25 怦然心动\n",
      "Top26 疯狂动物城\n",
      "Top27 天堂电影院\n",
      "Top28 蝙蝠侠：黑暗骑士\n",
      "Top29 活着\n",
      "Top30 十二怒汉\n",
      "Top31 鬼子来了\n",
      "Top32 少年派的奇幻漂流\n",
      "Top33 指环王3：王者无敌\n",
      "Top34 搏击俱乐部\n",
      "Top35 天空之城\n",
      "Top36 控方证人\n",
      "Top37 飞屋环游记\n",
      "Top38 大话西游之月光宝盒\n",
      "Top39 罗马假日\n",
      "Top40 窃听风暴\n",
      "Top41 两杆大烟枪\n",
      "Top42 摔跤吧！爸爸\n",
      "Top43 飞越疯人院\n",
      "Top44 闻香识女人\n",
      "Top45 哈尔的移动城堡\n",
      "Top46 辩护人\n",
      "Top47 死亡诗社\n",
      "Top48 V字仇杀队\n",
      "Top49 海豚湾\n",
      "Top50 教父2\n",
      "Top51 指环王2：双塔奇兵\n",
      "Top52 指环王1：魔戒再现\n",
      "Top53 美丽心灵\n",
      "Top54 饮食男女\n",
      "Top55 情书\n",
      "Top56 素媛\n",
      "Top57 狮子王\n",
      "Top58 美国往事\n",
      "Top59 钢琴家\n",
      "Top60 小鞋子\n",
      "Top61 七宗罪\n",
      "Top62 被嫌弃的松子的一生\n",
      "Top63 致命魔术\n",
      "Top64 天使爱美丽\n",
      "Top65 本杰明·巴顿奇事\n",
      "Top66 西西里的美丽传说\n",
      "Top67 黑客帝国\n",
      "Top68 音乐之声\n",
      "Top69 让子弹飞\n",
      "Top70 拯救大兵瑞恩\n",
      "Top71 看不见的客人\n",
      "Top72 低俗小说\n",
      "Top73 勇敢的心\n",
      "Top74 剪刀手爱德华\n",
      "Top75 末代皇帝\n",
      "Top76 沉默的羔羊\n",
      "Top77 大闹天宫\n",
      "Top78 蝴蝶效应\n",
      "Top79 春光乍泄\n",
      "Top80 入殓师\n",
      "Top81 心灵捕手\n",
      "Top82 哈利·波特与魔法石\n",
      "Top83 玛丽和马克思\n",
      "Top84 阳光灿烂的日子\n",
      "Top85 布达佩斯大饭店\n",
      "Top86 禁闭岛\n",
      "Top87 猫鼠游戏\n",
      "Top88 幽灵公主\n",
      "Top89 第六感\n",
      "Top90 重庆森林\n",
      "Top91 狩猎\n",
      "Top92 致命ID\n",
      "Top93 断背山\n",
      "Top94 穿条纹睡衣的男孩\n",
      "Top95 大鱼\n",
      "Top96 加勒比海盗\n",
      "Top97 告白\n",
      "Top98 一一\n",
      "Top99 甜蜜蜜\n",
      "Top100 阿凡达\n",
      "Finish Crawl!\n"
     ]
    }
   ],
   "source": [
    "import urllib.error\n",
    "import urllib.request\n",
    "import urllib\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "# Define a Python class, what is inside the () means this class extends from which class\n",
    "# Object is the class that every class will extend\n",
    "# The method __init__ is the constructor in Python\n",
    "# 'self' in Python is like 'this' in Java, means the object itself\n",
    "class DoubanCrawler(object):\n",
    "    \n",
    "    # Initialization\n",
    "    def __init__(self):\n",
    "        self.page = 1\n",
    "        self.url = \"http://movie.douban.com/top250?start={page}&filter=&type=\"\n",
    "        self.datas = []\n",
    "        self.top_num = 1\n",
    "        print(\"Ready to crawl Douban's movie data ...\")\n",
    "        \n",
    "    # Get the content of a page\n",
    "    def getpage(self, cur_page):\n",
    "        url = self.url\n",
    "        try:\n",
    "            # (cur_page -1) * 25 is the number of the first item of each page (because each page shows 25 items), which is the value of 'start'\n",
    "            my_page = urllib.request.urlopen(url.format(page = (cur_page - 1) * 25)).read().decode(\"utf-8\")\n",
    "        except urllib.error.URLError:\n",
    "            if hasattr(e, \"code\"):\n",
    "                print(\"The server couldn't response to the request.\")\n",
    "                print(\"Error code: %s\" % e.code)\n",
    "            elif hasattr(e, \"reason\"):\n",
    "                print(\"Failed to reach the server. Please check your url and refer to the Error Message\")\n",
    "                print(\"Error Message: %s\" % e.reason)\n",
    "        return my_page\n",
    "        \n",
    "    # Return the HTML of the page \n",
    "    def find_title(self, my_page) :\n",
    "        temp = []\n",
    "        movie_items = re.findall(r'<span.*?class=\"title\">(.*?)</span>', my_page, re.S)\n",
    "        for index, item in enumerate(movie_items):\n",
    "            if item.find(\"&nbsp\") == -1:\n",
    "                temp.append(\"Top\" + str(self.top_num) + \" \" + item)\n",
    "                self.top_num += 1\n",
    "        self.datas.extend(temp)\n",
    "    \n",
    "    def start(self) :\n",
    "        \"\"\"\n",
    "        This is the entry of the Crawler, it also controls the number of pages that will be crawled\n",
    "        \"\"\"\n",
    "        while self.page <= 4 :\n",
    "            my_page = self.getpage(self.page)\n",
    "            self.find_title(my_page)\n",
    "            self.page += 1\n",
    "    \n",
    "def main():\n",
    "    now = datetime.datetime.now()\n",
    "    print(\"\"\"\n",
    "    #################################################################\n",
    "        A simple web crawler to find out the top 100 movies in Douban\n",
    "                          Author: Sophie Song\n",
    "                            Version: 0.0.1\n",
    "                           Date: {date}\n",
    "    #################################################################\n",
    "\"\"\".format(date = str(now)))\n",
    "    crawler = DoubanCrawler()\n",
    "    crawler.start()\n",
    "    for item in crawler.datas:\n",
    "        print(item)\n",
    "    print(\"Finish Crawl!\")\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
